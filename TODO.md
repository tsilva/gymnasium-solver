- BUG: early stopping at epoch 39 with eval mean reward 721.80 (wrong)
- fix duplicate metric logging bug
- add alert support to metric tracker
- train for convergence without deterministic policy
- add support for non subprocenv
- make best model be saved to wandb
- log results to huggingface?
- TODO: make evaluation run in background and keep a mean reward window, it picks up the model params set up in it, runs N envs in sequence with N workers and 
- Write wandb diagnostics script, use claude desktop to debug
- run eval in background thread (always)
- run eval in background thread (always)
- add environment normalization support
- benchmark against rlzoo with same hyperparameters
- add support for plotting charts as text and feeding to llm, check how end of training does it
- track environment stats, observarion stats, reward distributions, etc
- shared backbone support is showing parts has being in evaluation mode during training, fix it
- change api to match sb3
- add a2c support
- normalization support through our own env wrapper
- track selected action distribution
- add support for conitnous environments
- align rollout collector with sb3
- training not working with data loader n_workers > 1
- Early stopping at epoch 39 with eval mean reward 807.80 >= threshold 475