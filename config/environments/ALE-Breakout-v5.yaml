# ALE/Breakout-v5 configuration with OCAtari-derived object features

# =====================
# Environment Specification
# =====================
spec: &spec
  source: https://ale.farama.org/environments/breakout/
  description: Deflect the ball with the paddle to clear bricks without losing lives.
  goal: clear all bricks without losing lives

  render_fps: 60

  action_space:
    discrete: 18
    labels:
      0: NOOP
      1: FIRE
      2: UP
      3: RIGHT
      4: LEFT
      5: DOWN
      6: UPRIGHT
      7: UPLEFT
      8: DOWNRIGHT
      9: DOWNLEFT
      10: UPFIRE
      11: RIGHTFIRE
      12: LEFTFIRE
      13: DOWNFIRE
      14: UPRIGHTFIRE
      15: UPLEFTFIRE
      16: DOWNRIGHTFIRE
      17: DOWNLEFTFIRE
    valid: [0, 1, 3, 4]  # NOOP, FIRE, RIGHT, LEFT
 
  observation_space:
    default: rgb
    variants:
      rgb:
        shape: [210, 160, 3]
        dtype: uint8
      ram:
        shape: [128]
        dtype: uint8
      objects:
        shape: [10]
        dtype: float32
        components:
          - {name: Paddle.x, range: [-1.0, 1.0]}
          - {name: Paddle.dx, range: [-1.0, 1.0]}
          - {name: Ball.x, range: [-1.0, 1.0]}
          - {name: Ball.y, range: [-1.0, 1.0]}
          - {name: Ball.dx, range: [-1.0, 1.0]}
          - {name: Ball.dy, range: [-1.0, 1.0]}
          - {name: Ball.visible, range: [-1.0, 1.0]}
          - {name: Ball.minusPaddle.x, range: [-1.0, 1.0]}
          - {name: Ball.minusPaddle.y, range: [-1.0, 1.0]}
          - {name: Blocks.remaining, range: [-1.0, 1.0]}

  rewards:
    per_block: +1
    life_lost: -1
    range: [-1, 1]

  returns:
    range: [0, 432]
    threshold_solved: 400

  modes:
    values: [0, 1, 2, 3]
    default: 0

  difficulties:
    values: [0, 1, 2, 3]
    default: 0


# =====================
# environment specs
# =====================

# RGB spec
_spec_rgb: &spec_rgb
  <<: *spec
  action_space:
    discrete: 18
    valid: [0, 1, 3, 4]  # NOOP, FIRE, RIGHT, LEFT
    labels:
      0: NOOP
      1: FIRE
      2: UP
      3: RIGHT
      4: LEFT
      5: DOWN
      6: UPRIGHT
      7: UPLEFT
      8: DOWNRIGHT
      9: DOWNLEFT
      10: UPFIRE
      11: RIGHTFIRE
      12: LEFTFIRE
      13: DOWNFIRE
      14: UPRIGHTFIRE
      15: UPLEFTFIRE
      16: DOWNRIGHTFIRE
      17: DOWNLEFTFIRE
    note: "Uses full ALE action space (18 actions) with masking. Only 4 actions are meaningful for Breakout."
  observation_space:
    default: rgb
    variants:
      rgb:
        shape: [3, 210, 160]
        dtype: uint8
        note: RGB frames from ALE (channel-first format)

# Objects spec
_spec_objects: &spec_objects
  <<: *spec

# =====================
# env variants
# =====================

# Base env
_env: &env
  spec: *spec
  env_id: ALE/Breakout-v5

# Deterministic env
_env_deterministic: &env_deterministic
  <<: *env
  env_kwargs:
    repeat_action_probability: 0.0

# RGB env
_env_rgb: &env_rgb
  <<: *env
  spec: *spec_rgb
  obs_type: "rgb"
  accelerator: "gpu"
  model_id: cnn_nature

# Objects env
_env_objects: &env_objects
  <<: *env
  project_id: ALE-Breakout-v5_objects
  spec: *spec_objects
  obs_type: "objects"
  env_wrappers:
    - { id: BreakoutV5_FeatureExtractor }

# =====================
# configs
# =====================

###########################
# CONFIGS: obs_type = rgb
###########################

rgb_ppo: &rgb_ppo
  <<: *env_rgb
  project_id: ALE-Breakout-v5_rgb
  algo_id: ppo
  description: "PPO with 4-frame grayscale stacks (84x84) via ALE atari vectorization"
  
  #max_env_steps: 20e6

  # TODO: test async vectorization, if faster apply by default to all atari envs if n_envs > 1
  n_envs: 32
  n_steps: 256
  #policy_lr: 0.00025
  #ent_coef: 0.0
  #ent_coef: 0.02
  #n_epochs: 3 
  #clip_range: 0.1
  #batch_size: 512

  # Set training budget (required for schedules)
  max_env_steps: 50e6

  # Add entropy decay (CRITICAL - forces policy to commit)
  ent_coef:
    start: 0.01
    end: 0.001
    from: 0.0
    to: 0.5
    schedule: linear

  # Add learning rate schedule
  policy_lr:
    start: 0.0025
    end: 0.0
    schedule: linear

  # Increase batch size and epochs
  batch_size: 1024  # up from 512
  n_epochs: 4       # up from 3
  clip_range: 0.2   # up from 0.1
  
  eval_warmup_epochs: 200
  eval_freq_epochs: 100
  eval_episodes: 10

rgb_deterministic_ppo:
  <<: *rgb_ppo
  <<: *env_deterministic
  project_id: ALE-Breakout-v5_rgb_deterministic
  description: "PPO with RGB observations - deterministic version with ALE atari vectorization"
  

###########################
# CONFIGS: obs_type = objects
###########################

objects_ppo: &objects_ppo
  <<: *env_objects
  algo_id: ppo
  model_id: mlp_small
  description: "PPO using OCAtari object features for Breakout"
  eval_warmup_epochs: 125
  eval_freq_epochs: 10
  eval_episodes: 15

objects_deterministic_ppo:
  <<: *objects_ppo
  <<: *env_deterministic
  project_id: ALE-Breakout-v5_objects_deterministic
  spec: *spec_objects  # Override to use objects spec instead of base spec
  description: "PPO object features without sticky actions"
