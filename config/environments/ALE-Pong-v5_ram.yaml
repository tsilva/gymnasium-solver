# Pong with RAM observations challenge configurations

_base: &base
  env_id: ALE/Pong-v5
  obs_type: "ram"
  normalize_obs: "static"

ppo:
  <<: *base
  algo_id: ppo
  max_timesteps: 5e6
  n_envs: 8               # Reduced for better sample efficiency
  n_steps: 512             # Reduced for more frequent updates
  batch_size: 512          # Larger batches for stable gradients
  n_epochs: 10             # More epochs to better utilize data
  policy_lr: 0.0003    # Higher learning rate for faster learning
  eval_freq_epochs: 50     # Less frequent eval to focus on training
  eval_episodes: 10        # More episodes for reliable evaluation

reinforce:
  <<: *base
  algo_id: reinforce
  max_timesteps: 1e7
  n_envs: 8
  n_steps: 1024
  batch_size: 128
  policy_lr: 1e-3
  hidden_dims: [128, 128]
  max_epochs: 2000
