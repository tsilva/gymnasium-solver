# Acrobot standard challenge configurations

# =====================
# Environment Specification
# =====================
spec:
  source: https://gymnasium.farama.org/environments/classic_control/acrobot/
  description: Swing the double pendulum to raise the end effector above a threshold.
  goal: end effector above threshold height

  action_space:
    discrete: 3
    labels: {0: torque_negative, 1: torque_zero, 2: torque_positive}

  observation_space:
    default: state
    variants:
      state:
        shape: [6]
        dtype: float32
        components:
          - {name: cos(theta1), range: [-1.0, 1.0]}
          - {name: sin(theta1), range: [-1.0, 1.0]}
          - {name: cos(theta2), range: [-1.0, 1.0]}
          - {name: sin(theta2), range: [-1.0, 1.0]}
          - {name: thetaDot1, range: [-inf, inf]}
          - {name: thetaDot2, range: [-inf, inf]}

  rewards:
    per_step: -1
    range: [-500, 0]

  returns:
    threshold_solved: -100


# =====================
# Configuration Anchors
# =====================

_env: &env
  env_id: Acrobot-v1
  max_env_steps: 1e6
  eval_freq_epochs: 10
  eval_episodes: 10
  batch_size: 64

_ppo: &ppo
  <<: *env
  algo_id: ppo
  n_envs: 8
  n_epochs: 4
  n_steps: 256
  gae_lambda: 0.94
  ent_coef: 0.0

_reinforce: &reinforce
  <<: *env
  algo_id: reinforce
  n_envs: 16
  n_steps: 512
  policy_lr: 5e-4
  hidden_dims: [128, 128]
  max_epochs: 2000

# Standard PPO on Acrobot - baseline configuration for acrobot swing-up task
ppo:
  <<: *ppo
  description: "Standard PPO on Acrobot - baseline configuration for acrobot swing-up task"

# Standard REINFORCE on Acrobot - basic policy gradient baseline
reinforce:
  <<: *reinforce
  description: "Standard REINFORCE on Acrobot - basic policy gradient baseline"
