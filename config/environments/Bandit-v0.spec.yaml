# Bandit-v0
source: local gym_envs.mab_env.MultiArmedBanditEnv
description: Stateless multi-armed bandit; pull an arm to receive a stochastic reward.

action_space:
  discrete: 10

observation_space:
  default: constant_zero
  variants:
    constant_zero:
      shape: [n_arms]
      dtype: float32
      range: [0, 0]

rewards:
  distribution: Gaussian per-arm; reward ~ N(means[i], stds[i])
  range: [-inf, inf]

returns:
  episodic: reward per step (episode_length typically 1)
  range: [-inf, inf]
  threshold_solved: max_arm_mean
