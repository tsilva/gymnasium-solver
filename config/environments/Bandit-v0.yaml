# =====================
# Environment Specification
# =====================
spec: &spec
  source: local gym_envs.mab_env.MultiArmedBanditEnv
  description: Stateless multi-armed bandit; pull an arm to receive a stochastic reward.

  action_space:
    discrete: 10

  observation_space:
    default: constant_zero
    variants:
      constant_zero:
        shape: [n_arms]
        dtype: float32
        range: [0, 0]

  rewards:
    distribution: Gaussian per-arm; reward ~ N(means[i], stds[i])
    range: [-inf, inf]

  returns:
    episodic: reward per step (episode_length typically 1)
    range: [-inf, inf]


# =====================
# env variants
# =====================

# Base env
_env: &env
  spec: *spec
  env_id: Bandit-v0
  accelerator: cpu
  env_kwargs:
    n_arms: 10
    means: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
    stds: 1
    episode_length: 1

# =====================
# configs
# =====================

ppo:
  <<: *env
  project_id: Bandit-v0
  algo_id: ppo
  model_id: mlp_small
  description: "PPO on Multi-Armed Bandit - standard configuration for bandit problem"
  max_env_steps: 20_000
  gamma: 1.0
  gae_lambda: 1.0
  n_steps: 64
  eval_warmup_epochs: 5
  eval_freq_epochs: 1
  n_epochs: 4
  policy_lr: {start: 4e-2, end: 0.0}

reinforce:
  <<: *env
  project_id: Bandit-v0
  algo_id: reinforce
  description: "REINFORCE on Multi-Armed Bandit - smoke testing configuration"
  max_env_steps: 20_000
  gamma: 1.0
  gae_lambda: 1.0
  n_steps: 64
  eval_warmup_epochs: 5
  eval_freq_epochs: 1
  policy_lr: {start: 4e-2, end: 0.0}
