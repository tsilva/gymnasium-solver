# MountainCar standard challenge configurations

__MountainCar-v0:
  project_id: "MountainCar-v0"
  env_id: MountainCar-v0
__MountainCar-v0_rewardshaping:
  inherits: __MountainCar-v0
  frame_stack: 3
  env_wrappers:
    - id: RewardShaper_MountainCarV0
      position_reward_scale: 100.0
      velocity_reward_scale: 10.0
      height_reward_scale: 50.0

MountainCar-v0_ppo:
  inherits: __MountainCar-v0
  algo_id: ppo
  n_envs: 16
  n_timesteps: 1e6
  n_epochs: 10
  batch_size: 128
  normalize: false
  n_steps: 128
  gamma: 0.999
  learning_rate: 3e-4
  hidden_dims: [256, 256]
  max_epochs: 1000

MountainCar-v0_reinforce:
  inherits: __MountainCar-v0
  algo_id: reinforce
  n_envs: 8
  n_steps: 1024
  batch_size: 128
  gamma: 0.999
  learning_rate: 1e-3
  hidden_dims: [128, 128]
  max_epochs: 2000

MountainCar-v0_rewardshaping_ppo:
  inherits: __MountainCar-v0_rewardshaping
  algo_id: ppo
  normalize: true
  n_envs: 16
  n_timesteps: 1e6
  n_epochs: 10
  batch_size: 128
  n_steps: 128
  gamma: 0.999
  learning_rate: 3e-4
  hidden_dims: [256, 256]
  max_epochs: 1000

MountainCar-v0_rewardshaping_reinforce:
  inherits: __MountainCar-v0_rewardshaping
  algo_id: reinforce
  normalize_obs: true
  n_envs: 8
  n_steps: 1024
  batch_size: 128
  gamma: 0.999
  learning_rate: 1e-3
  hidden_dims: [128, 128]
  use_baseline: true
  max_epochs: 2000
