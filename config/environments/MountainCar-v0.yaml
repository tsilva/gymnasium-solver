# MountainCar standard challenge configurations

# =====================
# Environment Specification
# =====================
spec:
  source: https://gymnasium.farama.org/environments/classic_control/mountain_car/
  description: Drive up the mountain by building momentum on a 1D track.

  action_space:
    discrete: 3
    labels: {0: push_left, 1: no_push, 2: push_right}

  observation_space:
    default: state
    variants:
      state:
        shape: [2]
        dtype: float32
        components:
          - {name: position, range: [-1.2, 0.6]}
          - {name: velocity, range: [-0.07, 0.07]}

  rewards:
    per_step: -1
    range: [-1, 0]

  returns:
    episodic: negative of steps to reach goal (lower is worse)
    range: [-200, 0]
    threshold_solved: -110


# =====================
# Configuration Anchors
# =====================

_env: &env
  env_id: MountainCar-v0
  eval_warmup_epochs: 50
  eval_freq_epochs: 10
  eval_episodes: 10
  hidden_dims: [128, 128]
  gamma: 0.999
  n_steps: 1024
  batch_size: 0.25

_env_rewardshaped: &env_rewardshaped
  <<: *env
  frame_stack: 3
  env_wrappers:
    - id: MountainCarV0_RewardShaper
      position_reward_scale: 100.0
      velocity_reward_scale: 10.0
      height_reward_scale: 50.0

_ppo: &ppo
  <<: *env
  algo_id: ppo
  n_envs: 16
  n_epochs: 10
  policy_lr: 1e-4

_reinforce: &reinforce
  <<: *env
  algo_id: reinforce
  n_envs: 8
  policy_lr: 1e-3

# Standard PPO on MountainCar - baseline configuration for mountain car task
ppo:
  <<: *ppo
  description: "Standard PPO on MountainCar - baseline configuration for mountain car task"

# Standard REINFORCE on MountainCar - basic policy gradient baseline
reinforce:
  <<: *reinforce
  description: "Standard REINFORCE on MountainCar - basic policy gradient baseline"

# PPO with reward shaping - uses shaped rewards to guide learning up the mountain
ppo_rewardshaped:
  <<: [*env_rewardshaped, *ppo]
  max_env_steps: 1e6
  n_steps: 128
  batch_size: 128
  gamma: 0.999
  policy_lr: 3e-4
  hidden_dims: [256, 256]
  max_epochs: 1000
  description: "PPO with reward shaping - uses shaped rewards to guide learning up the mountain"

# REINFORCE with reward shaping - uses shaped rewards with policy gradient
reinforce_rewardshaped:
  <<: [*env_rewardshaped, *reinforce]
  max_env_steps: 1e6
  normalize_obs: true
  batch_size: 128
  gamma: 0.999
  hidden_dims: [128, 128]
  max_epochs: 2000
  description: "REINFORCE with reward shaping - uses shaped rewards with policy gradient"
