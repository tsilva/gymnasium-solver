# MountainCar standard challenge configurations

# =====================
# Environment Specification
# =====================
spec: &spec
  source: https://gymnasium.farama.org/environments/classic_control/mountain_car/
  description: Drive up the mountain by building momentum on a 1D track.

  action_space:
    discrete: 3
    labels: {0: push_left, 1: no_push, 2: push_right}

  observation_space:
    default: state
    variants:
      state:
        shape: [2]
        dtype: float32
        components:
          - {name: position, range: [-1.2, 0.6]}
          - {name: velocity, range: [-0.07, 0.07]}

  rewards:
    per_step: -1
    range: [-1, 0]

  returns:
    episodic: negative of steps to reach goal (lower is worse)
    range: [-200, 0]
    threshold_solved: -110


# =====================
# env variants
# =====================

# Base env
_env: &env
  spec: *spec
  env_id: MountainCar-v0
  accelerator: cpu

# Reward-shaped env
_env_rewardshaped: &env_rewardshaped
  <<: *env
  env_wrappers:
    - id: MountainCarV0_RewardShaper
      position_reward_scale: 100.0
      velocity_reward_scale: 10.0
      height_reward_scale: 50.0

# Curiosity-driven env
_env_curiosity: &env_curiosity
  <<: *env
  env_wrappers:
    - id: MountainCarV0_StateCountBonus
      position_bins: 50
      velocity_bins: 50
      bonus_scale: 0.1
      bonus_type: count

# =====================
# configs
# =====================

ppo: &ppo
  <<: *env
  project_id: MountainCar-v0
  algo_id: ppo
  model_id: mlp_medium
  description: "Standard PPO on MountainCar - baseline configuration for mountain car task"
  eval_freq_epochs: 1
  eval_episodes: 10
  n_steps: 1024
  gamma: 0.999
  policy_lr: 1e-4
  ent_coef: 0.03

ppo_rewardshaped:
  <<: *env_rewardshaped
  algo_id: ppo
  project_id: MountainCar-v0_rewardshaped
  description: "PPO with reward shaping - uses shaped rewards to guide learning up the mountain"
 
ppo_curiosity:
  <<: *env_curiosity
  project_id: MountainCar-v0_curiosity
  algo_id: ppo
  description: "PPO with curiosity-driven exploration bonus based on state visitation counts"
  n_envs: 64
  n_steps: 1024
  batch_size: 0.25
  ent_coef: 0.03
  policy_lr: 1e-2