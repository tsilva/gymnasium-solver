# MountainCar standard challenge configurations

_env: &env
  env_id: MountainCar-v0
  eval_warmup_epochs: 50
  eval_freq_epochs: 10
  eval_episodes: 10
  hidden_dims: [128, 128]
  gamma: 0.999

_env_rewardshaped: &env_rewardshaped
  <<: *env
  frame_stack: 3
  env_wrappers:
    - id: MountainCarV0_RewardShaper
      position_reward_scale: 100.0
      velocity_reward_scale: 10.0
      height_reward_scale: 50.0

_ppo: &ppo
  <<: *env
  algo_id: ppo
  n_envs: 16
  n_steps: 1024
  batch_size: 0.25
  n_epochs: 10
  policy_lr: 1e-4

_reinforce: &reinforce
  <<: *env
  algo_id: reinforce
  n_envs: 8
  n_steps: 1024
  batch_size: 0.25
  policy_lr: 1e-3

ppo:
  <<: *ppo

reinforce:
  <<: *reinforce

ppo_rewardshaped:
  <<: [*env_rewardshaped, *ppo]
  max_timesteps: 1e6
  n_steps: 128
  batch_size: 128
  gamma: 0.999
  policy_lr: 3e-4
  hidden_dims: [256, 256]
  max_epochs: 1000

reinforce_rewardshaped:
  <<: [*env_rewardshaped, *reinforce]
  max_timesteps: 1e6
  normalize_obs: true
  batch_size: 128
  gamma: 0.999
  hidden_dims: [128, 128]
  max_epochs: 2000

