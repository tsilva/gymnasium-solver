# Pong with object-based observations challenge configurations

# Concrete fixes (apply 2–4 at once, then re-evaluate after ~1–2M steps)
# - Exploration and update size
#   - ent_coef: increase slightly to 0.005–0.008. Start 0.006.
#   - learning_rate: add linear decay: learning_rate: lin_3e-4 to keep early speed but reduce late staleness.
#   - clip_range: widen to 0.2 with linear decay (clip_range: 0.2, clip_range_schedule: linear). This raises clip_fraction toward ~0.1–0.2.
# - Advantage signal and batch quality
#   - n_steps: 512 (rollout size 8192) to improve advantage SNR on long rallies.
#   - n_epochs: 4–6 instead of 10 to reduce overfitting per batch as rollout size grows. Try 6.
#   - batch_size: keep 1024 (8 minibatches of 8192). If GPU room, 2048.
#   - normalize_advantages: keep "batch".
# - Value head
#   - vf_coef: 0.7 to prioritize critic fit near plateau.
#   - hidden_dims: [256, 256] for more capacity on non-linear object dynamics.
# - Observation features
#   - Disable clipping in `PongV5_FeatureExtractor` (clip: false) so normalized features can exceed [0,1] if calibration MIN/MAX are off.
#   - Optionally recompute MIN/MAX from a longer random policy sweep, or enable `norm_obs: true` in config to stabilize feature scale.
# - Evaluation cadence
#   - eval_freq_epochs: 100 to reduce eval overhead (not a big factor, but keeps focus on training).

env_id: ALE/Pong-v5
n_timesteps: 1e7
obs_type: "objects"
env_wrappers:
  - id: PongV5_FeatureExtractor

ppo:
  algo_id: ppo
  n_envs: 32
  vf_coef: 0.7
  n_steps: 256
  batch_size: 2048 
  n_epochs: 6
  ent_coef: 0.006
  clip_range: lin_0.2 
  learning_rate: lin_3e-4 
  hidden_dims: [256, 256] 
  eval_freq_epochs: 50 
  eval_episodes: 10  

reinforce:
  algo_id: reinforce
  n_envs: 8
  n_steps: 1024
  batch_size: 128
  learning_rate: 1e-3
  hidden_dims: [128, 128]
  use_baseline: true
  max_epochs: 2000
