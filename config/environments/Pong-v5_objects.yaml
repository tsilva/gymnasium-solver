# Pong with object-based observations challenge configurations

__Pong-v5_objects:
  project_id: "Pong-v5_objects"
  env_id: ALE/Pong-v5
  obs_type: "objects"
  env_wrappers:
    - id: PongV5_FeatureExtractor

Pong-v5_objects_ppo:
  inherits: __Pong-v5_objects
  algo_id: ppo
  n_envs: 16
  n_steps: 256             # rollout size = 8 * 512 = 4096
  batch_size: 1024          # 4 minibatches per update
  n_epochs: 10             # More epochs to better utilize data
  ent_coef: 0.003          # Higher entropy for better exploration
  clip_range: 0.15                  # slightly tighter than 0.2 helps stability
  # TODO: implement
  #clip_range_vf: 0.2  # Value function clipping
  # TODO: ortho init
  # TODO: lr scheduler
  learning_rate: 3e-4      # Higher learning rate for faster learning
  hidden_dims: [128, 128]    # Larger network for complex patterns
  eval_freq_epochs: 50     # Less frequent eval to focus on training
  eval_episodes: 10        # More episodes for reliable evaluation
Pong-v5_objects_reinforce:
  inherits: __Pong-v5_objects
  algo_id: reinforce
  n_envs: 8
  n_steps: 1024
  batch_size: 128
  learning_rate: 1e-3
  hidden_dims: [128, 128]
  use_baseline: true
  max_epochs: 2000
