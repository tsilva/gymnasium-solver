# Pong with RGB observations challenge configurations

env_id: ALE/Pong-v5
obs_type: "rgb"
policy: 'cnn'
# CNN defaults suitable for 84x84 inputs
policy_kwargs:
  activation: relu
  channels: [32, 64, 64]
  kernel_sizes: [8, 4, 3]
  strides: [4, 2, 1]
grayscale_obs: true
resize_obs: true
frame_stack: 4
accelerator: 'gpu'
devices: 'auto'
eval_freq_epochs: 1
eval_episodes: 1

ppo:
  algo_id: ppo
  n_envs: 8
  n_steps: 256             # 8*256 = 2048 samples/update
  batch_size: 1024         # 2k rollout â†’ 2 minibatches of 1024
  n_epochs: 3
  clip_range: 0.1
  learning_rate: 1e-4      # Slightly lower LR for stability on pixels
  frame_stack: 4           # Improve temporal information (typical Atari default)
  activation: relu         # Use ReLU for CNNs
  eval_freq_epochs: 10    # Less frequent eval due to computational cost
  eval_episodes: 5

reinforce:
  algo_id: reinforce
  n_envs: 4                # Fewer envs due to computational complexity
  n_steps: 512
  batch_size: 64
  learning_rate: 1e-4      # Lower learning rate for CNN
  use_baseline: true
  max_epochs: 5000
