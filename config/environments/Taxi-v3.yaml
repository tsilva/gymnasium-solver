# Taxi standard challenge configurations

# =====================
# Environment Specification
# =====================
spec:
  source: https://gymnasium.farama.org/environments/toy_text/taxi/
  description: Navigate a taxi to pick up and drop off a passenger at a destination.

  action_space:
    discrete: 6
    labels: {0: south, 1: north, 2: east, 3: west, 4: pickup, 5: dropoff}

  observation_space:
    default: encoded_state
    variants:
      encoded_state: {n: 500, dtype: int64}

  rewards:
    per_step: -1
    successful_dropoff: +20
    illegal_action: -10
    range: [-10, 20]

  returns:
    episodic: cumulative over episode
    range: [-800, 20]
    threshold_solved: 8


# =====================
# Configuration Anchors
# =====================

_env: &env
  env_id: Taxi-v3
  ent_coef: 0.01
  n_envs: 16
  eval_freq_epochs: 10
  eval_episodes: 10
  env_wrappers:
    - id: DiscreteEncoder
      encoding: array

_ppo: &ppo
  <<: *env
  algo_id: ppo
  max_env_steps: 10e6
  n_steps: 1024
  batch_size: 4096
  n_epochs: 20
  clip_range: 0.2
  policy_lr: 1e-2
  hidden_dims: [4, 16]
  normalize_returns: "rollout"
  normalize_advantages: "batch"
  vf_coef: 0.25

_reinforce: &reinforce
  <<: *env
  algo_id: reinforce
  max_env_steps: 5e5
  n_steps: 256
  batch_size: 32
  policy_lr: 0.01
  hidden_dims: [128]

# PPO on Taxi - standard configuration for taxi navigation task
ppo:
  <<: *ppo
  description: "PPO on Taxi - standard configuration for taxi navigation task"

# REINFORCE on Taxi - basic policy gradient for taxi navigation
reinforce:
  <<: *reinforce
  description: "REINFORCE on Taxi - basic policy gradient for taxi navigation"
