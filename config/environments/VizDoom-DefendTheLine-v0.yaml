# =====================
# Environment Specification
# =====================
spec: &spec
  source: https://github.com/mwydmuch/ViZDoom/tree/master/scenarios#defend-the-line
  description: Defend a line by eliminating enemies approaching from a single direction.

  render_fps: 35

  action_space:
    multibinary: 8
    labels: {
      0: noop,
      1: move_forward,
      2: move_backward,
      3: move_left,
      4: move_right,
      5: turn_left,
      6: turn_right,
      7: attack
    }
    valid: [5, 6, 7]  # Only turn_left, turn_right, and attack available in this scenario

  observation_space:
    default: rgb
    variants:
      rgb:
        shape: [height, width, 3]
        dtype: uint8
        range: [0, 255]
        note: Height/width depend on the ViZDoom cfg; wrapper enforces RGB24 and HWC.

  rewards:
    description: Reward for kills and survival time; penalties on death.
    components:
      - {name: kill_reward, sign: positive}
      - {name: survival_time, sign: positive}
      - {name: death_penalty, value: -100.0}
    threshold_solved: 1000
    range: [-100, 2000]

# =====================
# env variants
# =====================

# Base env
_env: &env
  spec: *spec
  env_id: VizDoom-DefendTheLine-v0
  render_mode: 'rgb_array'
    # TODO: defaults are not being applied
  obs_type: rgb
  render_mode: 'rgb_array'
  policy_kwargs:
    channels: [32, 64, 64]
    kernel_sizes: [8, 4, 3]
    strides: [4, 2, 1]
  grayscale_obs: true
  resize_obs: [84, 84]
  frame_stack: 4

# =====================
# configs
# =====================

# TODO: try no frame stack (should train faster and still work)
# TODO: tune LR decay to minimize approxkl oob and cliprange oob
ppo:
  <<: *env
  project_id: VizDoom-DefendTheLine-v0
  algo_id: ppo
  description: "PPO on VizDoom DefendTheLine - standard configuration for line defense task"
  max_env_steps: 2e6
  n_envs: 32
  n_steps: 256
  batch_size: 0.25 # TODO: test if batch sizes make any difference
  n_epochs: 20

  policy_lr:
    start: 2.5e-4
    end: 2.5e-5

  ent_coef: 0.03
  #  start: 0.03
  #  end: 0.01
  
  eval_warmup_epochs: 10
  eval_freq_epochs: 10
  eval_episodes: 10
