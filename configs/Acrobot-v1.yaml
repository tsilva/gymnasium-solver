ppo:
  #normalize: true
  n_envs: 16
  #n_timesteps: !!float 1e6
  #policy: 'MlpPolicy'
  batch_size: 64
  n_steps: 256
  gae_lambda: 0.94
  gamma: 0.99
  n_epochs: 4
  ent_coef: 0.0
