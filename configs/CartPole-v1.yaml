ppo:
  n_envs: 8
  #n_timesteps: !!float 1e5
  #policy: 'MlpPolicy'
  n_epochs: 20
  n_steps: 32
  batch_size: 256
  gae_lambda: 0.8
  gamma: 0.98
  ent_coef: 0.0
  #learning_rate: lin_0.001
  clip_range: 0.2
  # TODO: add linear decay support
  #clip_range: lin_0.2

  # Frame stacking
  frame_stack: 3                       # Stack 2 frames for temporal information

  # TODO: deprecate these, follow rlzoo style
  hidden_dims: [64]                # Sufficient capacity for CartPole
  policy_lr: 1e-3                      # Default policy LR (overridden per algo below)
  normalize_obs: false                 # Normalize observations for better learning
  normalize_reward: false              # Reward normalization not needed for CartPole