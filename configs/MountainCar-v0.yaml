ppo:
  #normalize: true
  n_envs: 16
  #n_timesteps: !!float 1e6
  #policy: 'MlpPolicy'
  n_steps: 16
  batch_size: 64
  gae_lambda: 0.98
  gamma: 0.99
  n_epochs: 4
  ent_coef: 0.2