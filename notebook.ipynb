{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae7ff8f",
   "metadata": {},
   "source": [
    "# Environment Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "768cf7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Enable autoreloading of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a074cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_ID = \"CartPole-v1\"\n",
    "#ENV_ID = \"LunarLander-v3\"\n",
    "#ALGORITHM = \"reinforce\"\n",
    "ALGORITHM = \"ppo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b028503",
   "metadata": {},
   "source": [
    "Load secrets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5101c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsilva_notebook_utils.colab import load_secrets_into_env\n",
    "\n",
    "_ = load_secrets_into_env([\n",
    "    'WANDB_API_KEY'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d847b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config for CartPole-v1 with ppo algorithm:\n",
      "RLConfig(env_id='CartPole-v1', seed=42, max_epochs=-1, gamma=0.99, lam=0.95, clip_epsilon=0.2, batch_size=256, train_rollout_steps=512, eval_interval=20, eval_episodes=5, reward_threshold=475, policy_lr=0.001, value_lr=0.001, hidden_dims=(32,), entropy_coef=0.01, normalize=False, mean_reward_window=100, rollout_interval=1)\n"
     ]
    }
   ],
   "source": [
    "from utils.config import load_config\n",
    "\n",
    "# Load configuration from YAML files\n",
    "CONFIG = load_config(ENV_ID, ALGORITHM)\n",
    "print(f\"Loaded config for {ENV_ID} with {ALGORITHM} algorithm:\")\n",
    "print(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90fd389",
   "metadata": {},
   "source": [
    "Build environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7605ffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Info (DummyVecEnv with 1 envs)\n",
      "  Env ID: CartPole-v1\n",
      "  Observation space: Box(low=[-4.8, -inf, -0.419, -inf], high=[4.8, inf, 0.419, inf], shape=(4,), dtype=float32)\n",
      "  Action space: Discrete(2)\n",
      "  Max episode steps: 500\n"
     ]
    }
   ],
   "source": [
    "from tsilva_notebook_utils.gymnasium import log_env_info\n",
    "from utils.environment import setup_environment\n",
    "\n",
    "# Setup environment with configuration\n",
    "build_env_fn = setup_environment(CONFIG)\n",
    "\n",
    "# Test building env\n",
    "env = build_env_fn(CONFIG.seed)\n",
    "log_env_info(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123f099b",
   "metadata": {},
   "source": [
    "Define models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6bad226",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SyncRolloutCollector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_agent, create_trainer\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsilva_notebook_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_default_device\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Get environment dimensions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/tsilva/gymnasium-solver/utils/training.py:12\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlearners\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreinforce\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m REINFORCELearner\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PolicyNet, ValueNet\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_agent\u001b[39m(config, build_env_fn, obs_dim, act_dim, algorithm=\u001b[38;5;28;01mNone\u001b[39;00m, rollout_collector_cls=\u001b[43mSyncRolloutCollector\u001b[49m, n_envs=\u001b[32m1\u001b[39m):\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create RL agent based on algorithm configuration.\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Create rollout collector env\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'SyncRolloutCollector' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.training import create_agent, create_trainer\n",
    "from tsilva_notebook_utils.torch import get_default_device\n",
    "\n",
    "# Get environment dimensions\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.n if hasattr(env.action_space, 'n') else env.action_space.shape[0]\n",
    "\n",
    "# Debug device information\n",
    "print(f\"Default device: {get_default_device()}\")\n",
    "\n",
    "# Create agent using utility function\n",
    "agent = create_agent(CONFIG, build_env_fn, obs_dim, act_dim, algorithm=ALGORITHM)\n",
    "\n",
    "# Debug model devices\n",
    "print(f\"Policy model device: {next(agent.policy_model.parameters()).device}\")\n",
    "if hasattr(agent, 'value_model') and agent.value_model is not None:\n",
    "    print(f\"Value model device: {next(agent.value_model.parameters()).device}\")\n",
    "print(f\"Rollout collector type: {type(agent.rollout_collector)}\")\n",
    "\n",
    "# Create trainer with W&B logging\n",
    "trainer = create_trainer(CONFIG, project_name=ENV_ID, run_name=f\"{ALGORITHM}-{CONFIG.seed}\")\n",
    "\n",
    "# Fit the model\n",
    "trainer.fit(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import evaluate_agent\n",
    "\n",
    "# Evaluate agent and render episodes\n",
    "# TODO: evaluate agent should receive rollout collector as an argument, not the agent and build_env_fn\n",
    "results = evaluate_agent(\n",
    "    agent, \n",
    "    build_env_fn, \n",
    "    n_episodes=8, \n",
    "    deterministic=True, \n",
    "    render=True,\n",
    "    grid=(2, 2), \n",
    "    text_color=(0, 0, 0), \n",
    "    out_dir=\"./tmp\"\n",
    ")\n",
    "\n",
    "print(f\"Mean reward: {results['mean_reward']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymnasium-solver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
